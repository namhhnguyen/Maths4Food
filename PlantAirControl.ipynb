{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Code"]},{"cell_type":"markdown","metadata":{},"source":["### Import"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os\n","import copy\n","import cma\n","import gymnasium as gym\n","import numpy as np\n","\n","from gymnasium.spaces import Dict, Box, Discrete, MultiDiscrete\n","\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","from stable_baselines3.common.env_util import make_vec_env\n","from stable_baselines3.common.callbacks import CheckpointCallback\n"]},{"cell_type":"markdown","metadata":{},"source":["### Utils"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def is_between(A, b):\n","    return A[0] < b <= A[1]\n","\n","def calculate_soil_evap_rate(T, R):\n","    A0 = 1.0\n","    A1 = 0.1\n","    return np.float32(A0*(1 + A1*T)*(1-R*0.01))\n","\n","def calculate_plant_evap_rate(T, R, light_on_off):\n","    A2 = 1.0\n","    A3 = 0.1\n","    A4 = 0.1\n","    return np.float32(A2*(1 + A3*T)*(1-R*0.01)*(1+A4*light_on_off))"]},{"cell_type":"markdown","metadata":{},"source":["### PlantAirControl Environment"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class PlantAirControl(gym.Env):\n","    # Constants are hard-coded for now but can set up to read from a spreadsheet\n","    CHAMBER_VOLUME = 1.0\n","    NON_LIGHT_HEAT = 0.5\n","    LIGHT_HEAT = 1.0\n","\n","    FAN_MAX_WATTAGE = 0.5 # kW\n","    HEAT_MAX_WATTAGE = 3 # kW\n","    COOL_MAX_WATTAGE = 3 # kW\n","\n","    FAN_MAX_AIR_INOUT_RATE = 1.0 \n","    HEAT_MAX_WATER_TEMP_UP_RATE = 1.0\n","    COOL_MAX_WATER_TEMP_DOWN_RATE = 1.0\n","\n","    DESIRED_TEMPS = [25.0, 32.0] # Celcius\n","    DESIRED_HUMIDS = [70.0, 85.0] # Percentage humidity\n","\n","    def __init__(self, render_mode=None,\n","                light_heat = LIGHT_HEAT,\n","                non_light_heat = NON_LIGHT_HEAT,\n","                chamber_volume = CHAMBER_VOLUME,\n","\n","                fan_max_wattage = FAN_MAX_WATTAGE,\n","                heat_max_wattage = HEAT_MAX_WATTAGE,\n","                cool_max_wattage = COOL_MAX_WATTAGE,\n","\n","                fan_max_air_inout_rate = FAN_MAX_AIR_INOUT_RATE,\n","                heat_max_water_temp_up_rate = HEAT_MAX_WATER_TEMP_UP_RATE,\n","                cool_max_water_temp_down_rate = COOL_MAX_WATER_TEMP_DOWN_RATE,\n","\n","                desired_temps = DESIRED_TEMPS,\n","                desired_humids = DESIRED_HUMIDS,\n","                ):\n","        # Set up some variables\n","        self.chamber_volume = np.float32(chamber_volume)\n","        self.light_heat = np.float32(light_heat)\n","        self.non_light_heat = np.float32(non_light_heat)\n","\n","        self.fan_max_wattage = np.float32(fan_max_wattage)\n","        self.heat_max_wattage = np.float32(heat_max_wattage)\n","        self.cool_max_wattage = np.float32(cool_max_wattage)\n","\n","        self.fan_max_air_inout_rate = np.float32(fan_max_air_inout_rate)\n","        self.heat_max_water_temp_up_rate = np.float32(heat_max_water_temp_up_rate)\n","        self.cool_max_water_temp_down_rate = np.float32(cool_max_water_temp_down_rate)\n","\n","        self.dersired_temps = np.float32(np.array(desired_temps))\n","        self.dersired_humids = np.float32(np.array(desired_humids))\n","\n","        # Specify the action_space\n","        self.action_space = MultiDiscrete([101]*3) # e.g., fan capacity, heating component capacity, cooling component capacity\n","        \n","        # Speicfy the observation_space\n","        self.observation_space = Dict({\"InTemp/InHumid/OutTemp/OutHumid/Energy\": Box(-100, 100, shape=(5,)),\n","                                       \"LightOnOff\": Discrete(2),\n","                                        \"Status\": Discrete(2),})\n","        \n","        # # Logger objects for longer time scale\n","        # self.inside_temps = []\n","        # self.inside_humids = []\n","        # self.outside_temps = []\n","        # self.outside_humids = []\n","        # self.fan_controls = []\n","        # self.heat_controls = []\n","        # self.cool_controls = []\n","\n","    def reset(self, seed=None):\n","        super().reset(seed=seed) # To enable self.np_random seeding\n","        rng = self.np_random\n","\n","        # Start state initialisation\n","        self.light_on_off = rng.integers(2)\n","\n","        self.inside_temp = rng.uniform(low = 15, high = 45)\n","        self.inside_humid = rng.uniform(low = 40, high = 90)\n","        self.outside_temp = rng.uniform(low = 0, high = 30)\n","        self.outside_humid = rng.uniform(low = 30, high = 70)\n","\n","        self.energy = 0\n","        \n","        self.plant_OK = 0 # 0 means not in the box yet, 1 means OK\n","        \n","        observation = {\"InTemp/InHumid/OutTemp/OutHumid/Energy\": np.float32(np.array([self.inside_temp, \n","                                                                          self.inside_humid, \n","                                                                          self.outside_temp,\n","                                                                          self.outside_humid,\n","                                                                          self.energy])),\n","                        \"LightOnOff\": self.light_on_off,\n","                        \"Status\": self.plant_OK}\n","\n","        info = {}\n","\n","        return observation, info\n","\n","    def step(self, action):\n","        # # Log things for longer time scale\n","        # self.inside_temps.append(self.inside_temp)\n","        # self.inside_humids.append(self.inside_humid)\n","        # self.outside_temps.append(self.outside_temp)\n","        # self.outside_humids.append(self.outside_humid)\n","        # self.fan_controls.append(action[0])\n","        # self.heat_controls.append(action[1])\n","        # self.cool_controls.append(action[2])\n","\n","        # Caculate some quantities\n","        self.plant_evap_rate = calculate_plant_evap_rate(self.inside_temp, self.inside_humid, self.light_on_off)\n","        self.soil_evap_rate = calculate_soil_evap_rate(self.inside_temp, self.inside_humid)\n","\n","        # Interprete action into parameters of mathematical model\n","        self.fan_air_inout_rate = (action[0] * self.fan_max_air_inout_rate)/100\n","        self.heat_water_temp_up_rate = (action[1] * self.heat_max_water_temp_up_rate)/100\n","        self.cool_water_temp_down_rate = (action[2] * self.cool_max_water_temp_down_rate)/100\n","\n","        self.fan_wattage = (action[0] * self.fan_max_wattage)/100\n","        self.heat_wattage = (action[1] * self.heat_max_wattage)/100\n","        self.cool_wattage = (action[2] * self.cool_max_wattage)/100\n","\n","        # Update observations via model for temp, humididty\n","        self.inside_temp += (self.non_light_heat + self.light_on_off * self.light_heat)/self.chamber_volume \\\n","            + 5.0 * self.fan_air_inout_rate * (self.outside_temp - self.inside_temp) \\\n","            + 5.0 * (2*self.heat_water_temp_up_rate - self.cool_water_temp_down_rate)\n","\n","        self.inside_humid += (self.plant_evap_rate + self.soil_evap_rate)/self.chamber_volume \\\n","            + 5.0 * self.fan_air_inout_rate * (self.outside_humid - self.inside_humid) \\\n","            + 5.0 * (self.heat_water_temp_up_rate - 2*self.cool_water_temp_down_rate)\n","\n","        self.energy += self.fan_wattage + self.heat_wattage + self.cool_wattage\n","\n","        if is_between(self.dersired_temps, self.inside_temp) and is_between(self.dersired_humids, self.inside_humid):\n","            self.plant_OK = 1\n","\n","        observation = {\"InTemp/InHumid/OutTemp/OutHumid/Energy\": np.float32(np.array([self.inside_temp, \n","                                                                          self.inside_humid, \n","                                                                          self.outside_temp,\n","                                                                          self.outside_humid,\n","                                                                          self.energy])),\n","                        \"LightOnOff\": self.light_on_off,\n","                        \"Status\": self.plant_OK}\n","\n","        # Reward\n","        reward = self.plant_OK * 10 - self.energy\n","\n","        terminated = True\n","\n","        info = {}\n","            \n","        return observation, reward, terminated, False, info"]},{"cell_type":"markdown","metadata":{},"source":["### Testing"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([35.932144, 45.467056, 21.66002 , 56.33034 ,  0.      ],\n","      dtype=float32), 'LightOnOff': 1, 'Status': 0}\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([21.44199, 57.80627, 21.66002, 56.33034,  5.135  ], dtype=float32), 'LightOnOff': 1, 'Status': 0}\n","The final reward is -5.135\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([24.194931, 55.39773 , 17.943037, 66.0645  ,  0.      ],\n","      dtype=float32), 'LightOnOff': 1, 'Status': 0}\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([15.391901, 69.96742 , 17.943037, 66.0645  ,  3.4     ],\n","      dtype=float32), 'LightOnOff': 1, 'Status': 0}\n","The final reward is -3.4000000000000004\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([32.043835 , 77.50847  ,  2.4209545, 48.85923  ,  0.       ],\n","      dtype=float32), 'LightOnOff': 1, 'Status': 0}\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([-1.778198 , 38.785362 ,  2.4209545, 48.85923  ,  4.19     ],\n","      dtype=float32), 'LightOnOff': 1, 'Status': 0}\n","The final reward is -4.19\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([32.388523, 71.1923  , 22.135592, 52.606907,  0.      ],\n","      dtype=float32), 'LightOnOff': 1, 'Status': 0}\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([22.560297, 49.912712, 22.135592, 52.606907,  2.12    ],\n","      dtype=float32), 'LightOnOff': 1, 'Status': 0}\n","The final reward is -2.12\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([17.593603, 48.360035, 10.174923, 47.73267 ,  0.      ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([18.976131, 50.108955, 10.174923, 47.73267 ,  2.86    ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","The final reward is -2.8600000000000003\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([34.76717 , 41.072044, 24.7075  , 64.15796 ,  0.      ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([17.259764, 86.00277 , 24.7075  , 64.15796 ,  1.38    ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","The final reward is -1.38\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([20.591284, 41.577137, 12.235357, 68.28223 ,  0.      ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([ -0.8620877, 126.08738  ,  12.235357 ,  68.28223  ,   3.79     ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","The final reward is -3.79\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([40.199337, 50.78708 , 17.94589 , 68.94229 ,  0.      ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([-35.950397, 118.279   ,  17.94589 ,  68.94229 ,   2.905   ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","The final reward is -2.9050000000000002\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([26.034529, 46.251343, 22.42813 , 38.52205 ,  0.      ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([ 6.864775,  8.08374 , 22.42813 , 38.52205 ,  2.385   ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","The final reward is -2.3850000000000002\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([32.867706, 55.68062 , 24.491983, 65.49225 ,  0.      ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","{'InTemp/InHumid/OutTemp/OutHumid/Energy': array([28.504412, 67.57315 , 24.491983, 65.49225 ,  4.34    ],\n","      dtype=float32), 'LightOnOff': 0, 'Status': 0}\n","The final reward is -4.34\n"]}],"source":["env = PlantAirControl()\n","episodes = 10\n","for episode in range(1, episodes + 1):\n","    obsINI, infoINI  = env.reset()\n","    print(obsINI)\n","    score = 0\n","    terminated = False\n","    truncated = False\n","\n","    while not terminated or truncated:\n","        action = env.action_space.sample()\n","        obs, reward, terminated, truncated, info = env.step(action)\n","        print(obs)\n","        print(f\"The final reward is {reward}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["log_path = os.path.join(os.getcwd(), \"Logs\")\n","save_path = os.path.join(os.getcwd(), \"Saved Models\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b15bda54b414310bd4878f1324432f9","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","</pre>\n"],"text/plain":["\n"]},"metadata":{},"output_type":"display_data"}],"source":[" # Set up the training environment\n","n_envs = 8\n","envs = make_vec_env(PlantAirControl, \n","                    n_envs=n_envs,\n","                    seed=42,\n","                    vec_env_cls=DummyVecEnv)\n","\n","# Set up the training model\n","model = PPO(\"MultiInputPolicy\", \n","            envs, \n","            verbose=0, \n","            tensorboard_log= os.path.join(log_path, \"Training\"), \n","            device = \"cpu\")\n","\n","# Set up checkpoints for during training\n","checkpoint_callback = CheckpointCallback(save_freq= 1e5, \n","                                            save_path=os.path.join(save_path, 'Checkpoints'),\n","                                            name_prefix='Checkpoint',\n","                                            save_replay_buffer=True,\n","                                            save_vecnormalize=True,\n","                                            verbose = 0)\n","\n","# Training\n","model.learn(2e6, callback = checkpoint_callback, progress_bar = True)\n","\n","# Save the model\n","model_final_path = os.path.join(save_path, 'Final') \n","model.save(model_final_path)"]},{"cell_type":"markdown","metadata":{},"source":["### Finetune with Evolutionary Strategies"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["model_final_path = os.path.join(os.getcwd(), \"Saved Models\", 'Final')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Turn RL problem into classic optimisation problem\n","class evaluate_action:\n","    def __init__(self, env, obsINI):\n","        self.env = env\n","        self.obsINI = obsINI\n","\n","    def __call__(self, action):\n","        action = np.floor(action)\n","        env_copy = copy.deepcopy(self.env)\n","        # Reset environment\n","        score = 0\n","        terminated = False\n","        truncated = False\n","        while not terminated or truncated:\n","            obs, reward, terminated, truncated, info = env_copy.step(action)\n","            score += reward\n","        fitness = 10 - score # This turns a maximisation problem into a minimsation problem\n","        return fitness"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Fine-tune model with Evolutionary Strategies\n","def ESOptimisation(env, obsINI):\n","    # Copy action\n","    model = PPO.load(model_final_path, env)\n","    action, _  = model.predict(obsINI, deterministic = True)\n","\n","    # Orginal model score\n","    env_copy = copy.deepcopy(env)\n","    original_score = 0\n","    terminated = False\n","    truncated = False\n","    while not terminated or truncated:\n","        obs, reward, terminated, truncated, info = env_copy.step(action)\n","        original_score += reward\n","\n","    # Finetune\n","    env_copy = copy.deepcopy(env)\n","    fun = evaluate_action(env_copy, obsINI)\n","    upper_buffer = np.float32(np.array([1 - 1e-7] * 3)) # Add buffer to give equal prob for Max action in ES \n","    upper_bounds = np.float32(np.array([100]*3)) + upper_buffer\n","    lower_bounds = np.float32(np.array([0] * 3))\n","\n","    # ES starting from no action\n","    x, es= cma.fmin2(fun, action, 25,\n","                      {'integer_variables': list(range(len(lower_bounds))),\n","                       'bounds': [lower_bounds, upper_bounds], \n","                       'tolflatfitness':10, \n","                       'tolfun': 1e-6,\n","                       'tolfunhist': 1e-7,\n","                       'verbose': -10},\n","                        restarts=2,\n","                        eval_initial_x = True,\n","                        )\n","\n","    final_score = 10 - fun(x)\n","    final_action = np.floor(x)\n","\n","    return final_action"]},{"cell_type":"markdown","metadata":{},"source":["### Deployment"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Create an environment\n","env = PlantAirControl()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Load RL model\n","model_final_path = os.path.join(os.getcwd(), \"Saved Models\", 'Final')\n","model = PPO.load(model_final_path, env)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The fine-tuned score is 0.0\n","The fine-tuned score is 10.0\n","The fine-tuned score is 9.58\n","The fine-tuned score is 9.985\n","The fine-tuned score is 0.0\n","The fine-tuned score is 0.0\n","The fine-tuned score is 0.0\n","The fine-tuned score is 9.78\n","The fine-tuned score is 9.73\n","The fine-tuned score is 9.31\n"]}],"source":["episodes = 10\n","for episode in range(1, episodes + 1):\n","    obsINI, infoINI  = env.reset(seed = episode)\n","    action = ESOptimisation(env, obsINI)\n","    score = 0\n","    terminated = False\n","    truncated = False\n","\n","    while not terminated or truncated:\n","        obs, reward, terminated, truncated, info = env.step(action)\n","        score += reward\n","        print(f\"The fine-tuned score is {score}\")"]}],"metadata":{"kernelspec":{"display_name":"RayEnv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
